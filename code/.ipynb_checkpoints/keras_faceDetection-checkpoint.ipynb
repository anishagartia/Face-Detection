{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishagartia/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import  SGD\n",
    "import keras.backend as k\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Train data...\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/'; \n",
    "train_path_pos = os.path.join(data_path, 'caltech_faces/Caltech_CropFaces'); #Positive training examples. 36x36 head crops\n",
    "non_face_scn_path = os.path.join(data_path, 'train_non_face_scenes'); #We can mine random or hard negatives from here\n",
    "test_scn_path = os.path.join(data_path,'test_scenes/test_jpg'); #CMU+MIT test scenes\n",
    "# test_scn_path = fullfile(data_path,'extra_test_scenes'); #Bonus scenes\n",
    "label_path = os.path.join(data_path,'test_scenes/ground_truth_bboxes.txt'); #the ground truth face locations in the test set\n",
    "        \n",
    "TrainPosPaths = []\n",
    "for i in glob.glob(os.path.join(train_path_pos, '*.jpg')):\n",
    "    TrainPosPaths.append(i)\n",
    "    \n",
    "TrainNegPaths = []\n",
    "for i in glob.glob(os.path.join(non_face_scn_path, '*.jpg')):\n",
    "    TrainNegPaths.append(i)    \n",
    "    \n",
    "TestPaths = []\n",
    "for i in glob.glob(os.path.join(test_scn_path, '*.jpg')):\n",
    "    TestPaths.append(i)    \n",
    "\n",
    "print('Getting Train data...')    \n",
    "X_PosTrain = []   \n",
    "Label_PosTrain = []\n",
    "for i in TrainPosPaths:\n",
    "    imgRead = io.imread(i,as_grey=True)\n",
    "    X_PosTrain.append(imgRead)        \n",
    "    Label_PosTrain.append(1)  \n",
    "X_PosTrain = np.asarray(X_PosTrain)  \n",
    "    \n",
    "numSamples = 10000\n",
    "numImg = len(TrainNegPaths)\n",
    "numPatchPerImg = np.int(numSamples/numImg)\n",
    "X_NegTrain = []\n",
    "Label_NegTrain = []\n",
    "for i in TrainNegPaths:\n",
    "    imgRead = io.imread(i,as_grey=True)\n",
    "    randx = np.random.randint(0,imgRead.shape[1]-36, numPatchPerImg)\n",
    "    randy = np.random.randint(0,imgRead.shape[0]-36, numPatchPerImg)\n",
    "    for j in range(0,numPatchPerImg):\n",
    "        X_NegTrain.append(imgRead[randy[j]:randy[j]+36,randx[j]:randx[j]+36])    \n",
    "        Label_NegTrain.append(0)\n",
    "X_NegTrain = np.asarray(X_NegTrain)\n",
    "\n",
    "X_Train = np.vstack((X_PosTrain,X_NegTrain))\n",
    "X_Train = np.reshape(X_Train, (X_Train.shape[0],1, X_Train.shape[1], X_Train.shape[2]))\n",
    "Y_Train = np.hstack((Label_PosTrain,Label_NegTrain))\n",
    "\n",
    "X_Train = X_Train.astype('float32')\n",
    "X_Train /= 255\n",
    "\n",
    "#nb_classes = 2\n",
    "Y_Train = np.array(Y_Train)\n",
    "#Y_Train = np_utils.to_categorical(Y_Train, nb_classes)\n",
    "\n",
    "\n",
    "# print('Getting Test data...')  \n",
    "# X_Test = []   \n",
    "# for i in TestPaths:\n",
    "#     imgRead = io.imread(i,as_grey=True)\n",
    "#     X_Test.append(imgRead)     \n",
    "# X_Test = np.asarray(X_Test) \n",
    "# X_Test = np.reshape(X_Test, (X_Test.shape[0],1, X_Test.shape[1], X_Test.shape[2]))\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the Model\n"
     ]
    }
   ],
   "source": [
    "print('Creating the Model')\n",
    "weight_init=\"he_uniform\"\n",
    "activation=\"relu\"\n",
    "border_mode=\"valid\"\n",
    "nb_filter=[10,10,10,10,10]\n",
    "nb_row=[3,3,3,3,3]\n",
    "nb_col=[3,3,3,3,3]\n",
    "output_fc=[36,36]\n",
    "pool_size=(3,3)\n",
    "stride_size=(2,2)\n",
    "dropout_percent=0.5\n",
    "learning_rate=1e-3\n",
    "mommentum_update=0.9\n",
    "decay_rate=1e-6\n",
    "training_batch_size=10\n",
    "val_batch_size=10\n",
    "no_epoch=1000\n",
    "no_of_channels = 1\n",
    "img_row = 36\n",
    "img_col = 36\n",
    "nb_classes = 1\n",
    "loss=\"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# #Deepnet Archictecture\n",
    "# #c1\n",
    "# model.add(Convolution2D(nb_filter[0], nb_row[0], nb_col[0], border_mode=border_mode, input_shape=(no_of_channels,img_row,img_col),init=weight_init))\n",
    "# model.add(Activation(activation))\n",
    "# #m2\n",
    "# model.add(MaxPooling2D(pool_size = pool_size, strides = stride_size))\n",
    "# #c3\n",
    "# model.add(Convolution2D(nb_filter[1], nb_row[1], nb_col[1], border_mode=border_mode, init=weight_init))\n",
    "# model.add(Activation(activation))\n",
    "# #l4\n",
    "# model.add(LocallyConnected2D(nb_filter[2], nb_row[2], nb_col[2],border_mode=border_mode, init=weight_init))\n",
    "# model.add(Activation(activation))\n",
    "# # #l5\n",
    "# model.add(LocallyConnected2D(nb_filter[3], nb_row[3], nb_col[3],border_mode=border_mode, init=weight_init))\n",
    "# model.add(Activation(activation))\n",
    "# #L6\n",
    "# model.add(LocallyConnected2D(nb_filter[4], nb_row[4], nb_col[4],border_mode=border_mode, init=weight_init))\n",
    "# #Dropout\n",
    "# model.add(Dropout(dropout_percent))\n",
    "# model.add(Flatten())\n",
    "# #F7\n",
    "# model.add(Dense(output_fc[0],init=weight_init))\n",
    "# model.add(Activation(activation)) \n",
    "# #normalization l2 \n",
    "# #F8\n",
    "# # model.add(Dense(output_fc[1],init=weight_init))\n",
    "# model.add(Dense(nb_classes, activation='sigmoid',init=weight_init))\n",
    "# #learning process\n",
    "# sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=loss,optimizer='rmsprop',metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# earlystopping = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5, verbose=0, mode='auto')\n",
    "# model.fit(X_Train, Y_Train, batch_size=training_batch_size,  nb_epoch=no_epoch, callbacks=[earlystopping], validation_split=0.2)\n",
    "# #score = model.evaluate(X_Test, Y_Test, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Only Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16577, 1296)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train = X_Train.reshape(X_Train.shape[0],-1)\n",
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_Train.shape[1],)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 512)           664064      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           262656      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 512)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             513         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 927233\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=5e-3\n",
    "sgd = SGD(lr=learning_rate, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13261 samples, validate on 3316 samples\n",
      "Epoch 1/25\n",
      "13261/13261 [==============================] - 3s - loss: 0.1164 - acc: 0.9722 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 2/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0077 - acc: 0.9995 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 3/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 4/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 5/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0021 - acc: 0.9998 - val_loss: 9.0680e-04 - val_acc: 1.0000\n",
      "Epoch 6/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0016 - acc: 0.9998 - val_loss: 8.7654e-04 - val_acc: 1.0000\n",
      "Epoch 7/25\n",
      "13261/13261 [==============================] - 7s - loss: 0.0015 - acc: 0.9999 - val_loss: 7.7257e-04 - val_acc: 1.0000\n",
      "Epoch 8/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0012 - acc: 0.9998 - val_loss: 6.7263e-04 - val_acc: 1.0000\n",
      "Epoch 9/25\n",
      "13261/13261 [==============================] - 7s - loss: 0.0011 - acc: 0.9998 - val_loss: 4.9806e-04 - val_acc: 1.0000\n",
      "Epoch 10/25\n",
      "13261/13261 [==============================] - 7s - loss: 8.8379e-04 - acc: 0.9998 - val_loss: 4.3410e-04 - val_acc: 1.0000\n",
      "Epoch 11/25\n",
      "13261/13261 [==============================] - 7s - loss: 9.9958e-04 - acc: 0.9998 - val_loss: 4.0647e-04 - val_acc: 1.0000\n",
      "Epoch 12/25\n",
      "13261/13261 [==============================] - 7s - loss: 9.9221e-04 - acc: 0.9998 - val_loss: 4.0780e-04 - val_acc: 1.0000\n",
      "Epoch 13/25\n",
      "13261/13261 [==============================] - 7s - loss: 8.6414e-04 - acc: 0.9998 - val_loss: 4.3937e-04 - val_acc: 1.0000\n",
      "Epoch 14/25\n",
      "13261/13261 [==============================] - 7s - loss: 7.3008e-04 - acc: 0.9999 - val_loss: 3.5226e-04 - val_acc: 1.0000\n",
      "Epoch 15/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.8790e-04 - acc: 0.9999 - val_loss: 2.6965e-04 - val_acc: 1.0000\n",
      "Epoch 16/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.8069e-04 - acc: 1.0000 - val_loss: 2.9526e-04 - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.3698e-04 - acc: 0.9999 - val_loss: 2.5605e-04 - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      "13261/13261 [==============================] - 6s - loss: 4.6098e-04 - acc: 0.9999 - val_loss: 2.2401e-04 - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.5796e-04 - acc: 1.0000 - val_loss: 2.1195e-04 - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "13261/13261 [==============================] - 8s - loss: 4.3099e-04 - acc: 1.0000 - val_loss: 2.2686e-04 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.2791e-04 - acc: 0.9999 - val_loss: 2.0446e-04 - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "13261/13261 [==============================] - 7s - loss: 3.6210e-04 - acc: 1.0000 - val_loss: 1.8375e-04 - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.5800e-04 - acc: 0.9998 - val_loss: 1.9284e-04 - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "13261/13261 [==============================] - 7s - loss: 3.8586e-04 - acc: 1.0000 - val_loss: 1.9401e-04 - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.1109e-04 - acc: 0.9998 - val_loss: 1.9836e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c7c1630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', min_delta=1.05e-4, patience=5, verbose=0, mode='auto')\n",
    "model.fit(X_Train, Y_Train, batch_size=32, nb_epoch=25, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('nn_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-33f1b52e33cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydot_ng\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anishagartia/anaconda/lib/python3.5/site-packages/keras/utils/visualize_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     raise RuntimeError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     13\u001b[0m                        ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from pydot_ng import find_graphviz\n",
    "import pydot\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
