{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishagartia/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import  SGD\n",
    "import keras.backend as k\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Train data...\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/'; \n",
    "train_path_pos = os.path.join(data_path, 'caltech_faces/Caltech_CropFaces'); #Positive training examples. 36x36 head crops\n",
    "non_face_scn_path = os.path.join(data_path, 'train_non_face_scenes'); #We can mine random or hard negatives from here\n",
    "test_scn_path = os.path.join(data_path,'test_scenes/test_jpg'); #CMU+MIT test scenes\n",
    "# test_scn_path = fullfile(data_path,'extra_test_scenes'); #Bonus scenes\n",
    "label_path = os.path.join(data_path,'test_scenes/ground_truth_bboxes.txt'); #the ground truth face locations in the test set\n",
    "        \n",
    "TrainPosPaths = []\n",
    "for i in glob.glob(os.path.join(train_path_pos, '*.jpg')):\n",
    "    TrainPosPaths.append(i)\n",
    "    \n",
    "TrainNegPaths = []\n",
    "for i in glob.glob(os.path.join(non_face_scn_path, '*.jpg')):\n",
    "    TrainNegPaths.append(i)    \n",
    "    \n",
    "TestPaths = []\n",
    "for i in glob.glob(os.path.join(test_scn_path, '*.jpg')):\n",
    "    TestPaths.append(i)    \n",
    "\n",
    "print('Getting Train data...')    \n",
    "X_PosTrain = []   \n",
    "Label_PosTrain = []\n",
    "for i in TrainPosPaths:\n",
    "    imgRead = io.imread(i,as_grey=True)\n",
    "    X_PosTrain.append(imgRead)        \n",
    "    Label_PosTrain.append(1)  \n",
    "X_PosTrain = np.asarray(X_PosTrain)  \n",
    "    \n",
    "numSamples = 10000\n",
    "numImg = len(TrainNegPaths)\n",
    "numPatchPerImg = np.int(numSamples/numImg)\n",
    "X_NegTrain = []\n",
    "Label_NegTrain = []\n",
    "for i in TrainNegPaths:\n",
    "    imgRead = io.imread(i,as_grey=True)\n",
    "    randx = np.random.randint(0,imgRead.shape[1]-36, numPatchPerImg)\n",
    "    randy = np.random.randint(0,imgRead.shape[0]-36, numPatchPerImg)\n",
    "    for j in range(0,numPatchPerImg):\n",
    "        X_NegTrain.append(imgRead[randy[j]:randy[j]+36,randx[j]:randx[j]+36])    \n",
    "        Label_NegTrain.append(0)\n",
    "X_NegTrain = np.asarray(X_NegTrain)\n",
    "\n",
    "X_Train = np.vstack((X_PosTrain,X_NegTrain))\n",
    "X_Train = np.reshape(X_Train, (X_Train.shape[0],1, X_Train.shape[1], X_Train.shape[2]))\n",
    "Y_Train = np.hstack((Label_PosTrain,Label_NegTrain))\n",
    "\n",
    "X_Train = X_Train.astype('float32')\n",
    "X_Train /= 255\n",
    "\n",
    "#nb_classes = 2\n",
    "Y_Train = np.array(Y_Train)\n",
    "#Y_Train = np_utils.to_categorical(Y_Train, nb_classes)\n",
    "\n",
    "\n",
    "# print('Getting Test data...')  \n",
    "# X_Test = []   \n",
    "# for i in TestPaths:\n",
    "#     imgRead = io.imread(i,as_grey=True)\n",
    "#     X_Test.append(imgRead)     \n",
    "# X_Test = np.asarray(X_Test) \n",
    "# X_Test = np.reshape(X_Test, (X_Test.shape[0],1, X_Test.shape[1], X_Test.shape[2]))\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the Model\n"
     ]
    }
   ],
   "source": [
    "print('Creating the Model')\n",
    "weight_init=\"he_uniform\"\n",
    "activation=\"relu\"\n",
    "border_mode=\"valid\"\n",
    "nb_filter=[10,10,10,10,10]\n",
    "nb_row=[3,3,3,3,3]\n",
    "nb_col=[3,3,3,3,3]\n",
    "output_fc=[36,36]\n",
    "pool_size=(3,3)\n",
    "stride_size=(2,2)\n",
    "dropout_percent=0.5\n",
    "learning_rate=1e-3\n",
    "mommentum_update=0.9\n",
    "decay_rate=1e-6\n",
    "training_batch_size=10\n",
    "val_batch_size=10\n",
    "no_epoch=1000\n",
    "no_of_channels = 1\n",
    "img_row = 36\n",
    "img_col = 36\n",
    "nb_classes = 1\n",
    "loss=\"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFaces (https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Deepnet Archictecture\n",
    "#c1\n",
    "model.add(Convolution2D(nb_filter[0], nb_row[0], nb_col[0], border_mode=border_mode, input_shape=(no_of_channels,img_row,img_col),init=weight_init))\n",
    "model.add(Activation(activation))\n",
    "#m2\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = stride_size))\n",
    "#c3\n",
    "model.add(Convolution2D(nb_filter[1], nb_row[1], nb_col[1], border_mode=border_mode, init=weight_init))\n",
    "model.add(Activation(activation))\n",
    "#l4\n",
    "model.add(LocallyConnected2D(nb_filter[2], nb_row[2], nb_col[2],border_mode=border_mode, init=weight_init))\n",
    "model.add(Activation(activation))\n",
    "# #l5\n",
    "model.add(LocallyConnected2D(nb_filter[3], nb_row[3], nb_col[3],border_mode=border_mode, init=weight_init))\n",
    "model.add(Activation(activation))\n",
    "#L6\n",
    "model.add(LocallyConnected2D(nb_filter[4], nb_row[4], nb_col[4],border_mode=border_mode, init=weight_init))\n",
    "#Dropout\n",
    "model.add(Dropout(dropout_percent))\n",
    "model.add(Flatten())\n",
    "#F7\n",
    "model.add(Dense(output_fc[0],init=weight_init))\n",
    "model.add(Activation(activation)) \n",
    "#normalization l2 \n",
    "#F8\n",
    "# model.add(Dense(output_fc[1],init=weight_init))\n",
    "model.add(Dense(nb_classes, activation='sigmoid',init=weight_init))\n",
    "#learning process\n",
    "sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=loss,optimizer='rmsprop',metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 10, 34, 34)    100         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10, 34, 34)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 10, 16, 16)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 10, 14, 14)    910         maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 10, 14, 14)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "locallyconnected2d_1 (LocallyConn(None, 10, 12, 12)    131040      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 10, 12, 12)    0           locallyconnected2d_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "locallyconnected2d_2 (LocallyConn(None, 10, 10, 10)    91000       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 10, 10, 10)    0           locallyconnected2d_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "locallyconnected2d_3 (LocallyConn(None, 10, 8, 8)      58240       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10, 8, 8)      0           locallyconnected2d_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 640)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 36)            23076       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 36)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             37          activation_8[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 304403\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5, verbose=0, mode='auto')\n",
    "model.fit(X_Train, Y_Train, batch_size=training_batch_size,  nb_epoch=no_epoch, callbacks=[earlystopping], validation_split=0.2)\n",
    "#score = model.evaluate(X_Test, Y_Test, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Only Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16577, 1296)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train = X_Train.reshape(X_Train.shape[0],-1)\n",
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('nn_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(512,input_shape=(X_Train.shape[1],)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 512)           664064      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           262656      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 512)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             513         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 927233\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning_rate=5e-3\n",
    "# sgd = SGD(lr=learning_rate, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13261 samples, validate on 3316 samples\n",
      "Epoch 1/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.1207 - acc: 0.9687 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 2/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0077 - acc: 0.9995 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 3/25\n",
      "13261/13261 [==============================] - 6s - loss: 0.0038 - acc: 0.9998 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 4/25\n",
      "13261/13261 [==============================] - 9s - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 5/25\n",
      "13261/13261 [==============================] - 9s - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 6/25\n",
      "13261/13261 [==============================] - 9s - loss: 0.0017 - acc: 0.9998 - val_loss: 7.6938e-04 - val_acc: 1.0000\n",
      "Epoch 7/25\n",
      "13261/13261 [==============================] - 10s - loss: 0.0013 - acc: 0.9999 - val_loss: 7.9499e-04 - val_acc: 1.0000\n",
      "Epoch 8/25\n",
      "13261/13261 [==============================] - 10s - loss: 0.0011 - acc: 0.9998 - val_loss: 5.5685e-04 - val_acc: 1.0000\n",
      "Epoch 9/25\n",
      "13261/13261 [==============================] - 10s - loss: 0.0011 - acc: 0.9998 - val_loss: 5.7479e-04 - val_acc: 1.0000\n",
      "Epoch 10/25\n",
      "13261/13261 [==============================] - 9s - loss: 0.0011 - acc: 0.9998 - val_loss: 5.3545e-04 - val_acc: 1.0000\n",
      "Epoch 11/25\n",
      "13261/13261 [==============================] - 8s - loss: 9.5947e-04 - acc: 0.9998 - val_loss: 4.6775e-04 - val_acc: 1.0000\n",
      "Epoch 12/25\n",
      "13261/13261 [==============================] - 7s - loss: 8.2142e-04 - acc: 0.9998 - val_loss: 3.8125e-04 - val_acc: 1.0000\n",
      "Epoch 13/25\n",
      "13261/13261 [==============================] - 7s - loss: 7.1634e-04 - acc: 0.9998 - val_loss: 3.3951e-04 - val_acc: 1.0000\n",
      "Epoch 14/25\n",
      "13261/13261 [==============================] - 10s - loss: 6.7020e-04 - acc: 0.9999 - val_loss: 3.5424e-04 - val_acc: 1.0000\n",
      "Epoch 15/25\n",
      "13261/13261 [==============================] - 8s - loss: 6.3991e-04 - acc: 0.9998 - val_loss: 3.3045e-04 - val_acc: 1.0000\n",
      "Epoch 16/25\n",
      "13261/13261 [==============================] - 14s - loss: 6.2840e-04 - acc: 0.9998 - val_loss: 3.0211e-04 - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.3793e-04 - acc: 0.9998 - val_loss: 2.5368e-04 - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.8542e-04 - acc: 1.0000 - val_loss: 2.3384e-04 - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.1470e-04 - acc: 1.0000 - val_loss: 2.1428e-04 - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "13261/13261 [==============================] - 8s - loss: 4.3779e-04 - acc: 0.9999 - val_loss: 1.9596e-04 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "13261/13261 [==============================] - 7s - loss: 5.5962e-04 - acc: 0.9998 - val_loss: 2.0864e-04 - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "13261/13261 [==============================] - 9s - loss: 3.7415e-04 - acc: 1.0000 - val_loss: 1.9258e-04 - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "13261/13261 [==============================] - 10s - loss: 4.4839e-04 - acc: 0.9998 - val_loss: 1.8616e-04 - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "13261/13261 [==============================] - 7s - loss: 4.6641e-04 - acc: 0.9999 - val_loss: 1.8912e-04 - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "13261/13261 [==============================] - 6s - loss: 4.4830e-04 - acc: 0.9999 - val_loss: 1.9979e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1174b9438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# earlystopping = EarlyStopping(monitor='val_loss', min_delta=1.05e-4, patience=5, verbose=0, mode='auto')\n",
    "# model.fit(X_Train, Y_Train, batch_size=32, nb_epoch=25, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save('nn_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f9d731d0fa87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anishagartia/anaconda/lib/python3.5/site-packages/keras/utils/visualize_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     raise RuntimeError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     13\u001b[0m                        ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "# import pydot\n",
    "# from keras.utils.visualize_util import plot\n",
    "# plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
